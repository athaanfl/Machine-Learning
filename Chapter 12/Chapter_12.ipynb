{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 12: Custom Models and Training with TensorFlow - Notebook Reproduksi Kode\n",
        "\n",
        "Bab ini membahas bagaimana membuat komponen kustom di TensorFlow dan Keras,\n",
        "serta menulis loop pelatihan kustom menggunakan API tingkat rendah TensorFlow.\n",
        "\n",
        "Kita akan melihat:\n",
        "- Fungsi Kerugian Kustom (Custom Loss Functions).\n",
        "- Fungsi Aktivasi, Initializer, Regularizer, Constraint Kustom.\n",
        "- Model Kustom (menggunakan subclassing keras.Model).\n",
        "- Loop Pelatihan Kustom (Custom Training Loops) dengan tf.GradientTape.\n",
        "- Layer Kustom."
      ],
      "metadata": {
        "id": "AnX3EMF9_ldM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KPUocfSB_ieJ",
        "outputId": "593bcbeb-669d-459b-ad98-cbab67d7dcab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fungsi Kerugian Kustom (Huber Loss) ---\n",
            "\n",
            "Melatih model dengan Huber Loss kustom...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model dengan Huber Loss kustom berhasil dilatih.\n",
            "MSE pada set pengujian: 0.1589\n",
            "\n",
            "--- Fungsi Aktivasi Kustom (PReLU Sederhana) ---\n",
            "Melatih model dengan aktivasi PReLU kustom...\n",
            "Model dengan aktivasi kustom berhasil dilatih.\n",
            "\n",
            "--- Initializer Kustom (All Zeros) ---\n",
            "Melatih model dengan initializer kustom...\n",
            "Model dengan initializer kustom berhasil dilatih.\n",
            "\n",
            "--- Regularizer Kustom (L1 Custom) ---\n",
            "Melatih model dengan regularizer L1 kustom...\n",
            "Model dengan regularizer kustom berhasil dilatih.\n",
            "\n",
            "--- Constraint Kustom (Non-negative Weights) ---\n",
            "Melatih model dengan constraint kustom...\n",
            "Model dengan constraint kustom berhasil dilatih.\n",
            "\n",
            "--- Model Kustom (Subclassing keras.Model) ---\n",
            "\n",
            "Ringkasan Model Kustom (ResidualDNN):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'residual_dnn', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"residual_dnn\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"residual_dnn\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ res_block_0 (\u001b[38;5;33mResidualBlock\u001b[0m)     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ res_block_1 (\u001b[38;5;33mResidualBlock\u001b[0m)     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ res_block_2 (\u001b[38;5;33mResidualBlock\u001b[0m)     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ res_block_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ res_block_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ res_block_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Melatih model kustom (subclassing)...\n",
            "Model kustom (subclassing) berhasil dilatih.\n",
            "\n",
            "--- Loop Pelatihan Kustom ---\n",
            "\n",
            "Memulai loop pelatihan kustom...\n",
            "Epoch 1/10 - Loss: 4.8737, Val_loss: 7.2184\n",
            "Epoch 2/10 - Loss: 2.4089, Val_loss: 3.2489\n",
            "Epoch 3/10 - Loss: 1.6317, Val_loss: 1.2033\n",
            "Epoch 4/10 - Loss: 1.2309, Val_loss: 0.6442\n",
            "Epoch 5/10 - Loss: 1.0121, Val_loss: 0.5617\n",
            "Epoch 6/10 - Loss: 0.8859, Val_loss: 0.5203\n",
            "Epoch 7/10 - Loss: 0.8103, Val_loss: 0.4955\n",
            "Epoch 8/10 - Loss: 0.7627, Val_loss: 0.4965\n",
            "Epoch 9/10 - Loss: 0.7316, Val_loss: 0.5031\n",
            "Epoch 10/10 - Loss: 0.7092, Val_loss: 0.4616\n",
            "Loop pelatihan kustom selesai.\n",
            "\n",
            "--- Layer Kustom ---\n",
            "\n",
            "Melatih model dengan layer kustom...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model dengan layer kustom berhasil dilatih.\n",
            "\n",
            "Model dengan layer kustom disimpan. Mencoba memuat...\n",
            "Model dengan layer kustom berhasil dimuat.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ my_custom_dense_layer           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
              "│ (\u001b[38;5;33mDenseWithActivationAndBiasCon…\u001b[0m │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ my_custom_dense_layer_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
              "│ (\u001b[38;5;33mDenseWithActivationAndBiasCon…\u001b[0m │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ my_custom_dense_layer           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DenseWithActivationAndBiasCon…</span> │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ my_custom_dense_layer_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DenseWithActivationAndBiasCon…</span> │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,612\u001b[0m (1.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,612</span> (1.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Selesai Reproduksi Kode Chapter 12 ---\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import fetch_california_housing # Untuk dataset California Housing\n",
        "\n",
        "# Atur random seed untuk reproduksibilitas\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Path untuk menyimpan gambar plot\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"custom_nn\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "# Memuat Dataset Fashion MNIST\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full_fashion, y_train_full_fashion), (X_test_fashion, y_test_fashion) = fashion_mnist.load_data()\n",
        "\n",
        "X_valid_fashion, X_train_fashion = X_train_full_fashion[:5000] / 255.0, X_train_full_fashion[5000:] / 255.0\n",
        "y_valid_fashion, y_train_fashion = y_train_full_fashion[:5000], y_train_full_fashion[5000:]\n",
        "X_test_fashion = X_test_fashion / 255.0\n",
        "\n",
        "class_names_fashion = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "                       \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "\n",
        "# Memuat Dataset California Housing (untuk demonstrasi regresi)\n",
        "housing = fetch_california_housing()\n",
        "X_train_full_housing, X_test_housing, y_train_full_housing, y_test_housing = train_test_split(\n",
        "    housing.data, housing.target, random_state=42)\n",
        "X_train_housing, X_valid_housing, y_train_housing, y_valid_housing = train_test_split(\n",
        "    X_train_full_housing, y_train_full_housing, random_state=42)\n",
        "\n",
        "scaler_housing = StandardScaler()\n",
        "X_train_scaled_housing = scaler_housing.fit_transform(X_train_housing)\n",
        "X_valid_scaled_housing = scaler_housing.transform(X_valid_housing)\n",
        "X_test_scaled_housing = scaler_housing.transform(X_test_housing)\n",
        "\n",
        "# Fungsi pembantu untuk plot kurva pembelajaran (opsional, karena tidak semua bagian akan di-plot)\n",
        "def plot_learning_curves(history):\n",
        "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "    plt.grid(True)\n",
        "    # plt.gca().set_ylim(0, 1) # Jika metrik akurasi/loss\n",
        "    plt.title(\"Kurva Pembelajaran\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Metrik\")\n",
        "    plt.show()\n",
        "\n",
        "# --- 1. Fungsi Kerugian Kustom (Custom Loss Functions) ---\n",
        "# Contoh: Huber Loss - kurang sensitif terhadap outlier dibandingkan MSE.\n",
        "\n",
        "print(\"--- Fungsi Kerugian Kustom (Huber Loss) ---\")\n",
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    error = tf.abs(y_true - y_pred)\n",
        "    # Kondisi: jika error <= delta, gunakan 0.5 * error^2\n",
        "    # Jika error > delta, gunakan delta * error - 0.5 * delta^2\n",
        "    is_small_error = error < delta\n",
        "    squared_loss = 0.5 * tf.square(error)\n",
        "    linear_loss = delta * error - 0.5 * tf.square(delta)\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "\n",
        "# Membuat model sederhana untuk demonstrasi\n",
        "model_huber_loss = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train_scaled_housing.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Mengkompilasi model dengan custom loss\n",
        "# Penting: Saat menyimpan/memuat model dengan custom object, perlu custom_objects dict\n",
        "print(\"\\nMelatih model dengan Huber Loss kustom...\")\n",
        "model_huber_loss.compile(loss=huber_loss, optimizer=\"adam\")\n",
        "history_huber = model_huber_loss.fit(X_train_scaled_housing, y_train_housing, epochs=10,\n",
        "                                     validation_data=(X_valid_scaled_housing, y_valid_housing), verbose=0) # verbose=0 agar tidak membanjiri output\n",
        "print(\"Model dengan Huber Loss kustom berhasil dilatih.\")\n",
        "print(f\"MSE pada set pengujian: {model_huber_loss.evaluate(X_test_scaled_housing, y_test_housing, verbose=0):.4f}\")\n",
        "\n",
        "\n",
        "# --- 2. Fungsi Aktivasi, Initializer, Regularizer, Constraint Kustom ---\n",
        "\n",
        "# a. Fungsi Aktivasi Kustom (contoh: PReLU)\n",
        "print(\"\\n--- Fungsi Aktivasi Kustom (PReLU Sederhana) ---\")\n",
        "def custom_prelu(z, alpha=0.1): # Implementasi sederhana PReLU\n",
        "    return tf.where(z < 0, alpha * z, z)\n",
        "\n",
        "model_custom_activation = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, input_shape=X_train_scaled_housing.shape[1:]),\n",
        "    keras.layers.Activation(custom_prelu), # Menggunakan fungsi aktivasi kustom\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model_custom_activation.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "print(\"Melatih model dengan aktivasi PReLU kustom...\")\n",
        "model_custom_activation.fit(X_train_scaled_housing, y_train_housing, epochs=5, verbose=0)\n",
        "print(\"Model dengan aktivasi kustom berhasil dilatih.\")\n",
        "\n",
        "\n",
        "# b. Initializer Kustom (contoh: all zeros)\n",
        "print(\"\\n--- Initializer Kustom (All Zeros) ---\")\n",
        "def zero_initializer(shape, dtype=tf.float32):\n",
        "    return tf.zeros(shape, dtype=dtype)\n",
        "\n",
        "model_custom_initializer = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", kernel_initializer=zero_initializer,\n",
        "                        input_shape=X_train_scaled_housing.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model_custom_initializer.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "print(\"Melatih model dengan initializer kustom...\")\n",
        "model_custom_initializer.fit(X_train_scaled_housing, y_train_housing, epochs=1, verbose=0) # Epoch singkat karena zero init mungkin tidak bagus\n",
        "print(\"Model dengan initializer kustom berhasil dilatih.\")\n",
        "\n",
        "\n",
        "# c. Regularizer Kustom (contoh: L1 custom)\n",
        "print(\"\\n--- Regularizer Kustom (L1 Custom) ---\")\n",
        "# FIX: Mengubah fungsi biasa menjadi kelas yang mewarisi dari keras.regularizers.Regularizer\n",
        "class CustomL1Regularizer(keras.regularizers.Regularizer):\n",
        "    def __init__(self, strength):\n",
        "        self.strength = strength\n",
        "\n",
        "    def __call__(self, weight_matrix):\n",
        "        return self.strength * tf.reduce_sum(tf.abs(weight_matrix))\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"strength\": self.strength}\n",
        "\n",
        "model_custom_regularizer = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", kernel_regularizer=CustomL1Regularizer(0.01), # Menggunakan instance dari kelas kustom\n",
        "                        input_shape=X_train_scaled_housing.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model_custom_regularizer.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "print(\"Melatih model dengan regularizer L1 kustom...\")\n",
        "model_custom_regularizer.fit(X_train_scaled_housing, y_train_housing, epochs=5, verbose=0)\n",
        "print(\"Model dengan regularizer kustom berhasil dilatih.\")\n",
        "\n",
        "\n",
        "# d. Constraint Kustom (contoh: Non-negative weights)\n",
        "print(\"\\n--- Constraint Kustom (Non-negative Weights) ---\")\n",
        "# FIX: Mengubah fungsi biasa menjadi kelas yang mewarisi dari keras.constraints.Constraint\n",
        "class NonNegWeights(keras.constraints.Constraint):\n",
        "    def __call__(self, weights):\n",
        "        return tf.cast(tf.greater_equal(weights, 0.), tf.float32) * weights # Set negatif ke 0\n",
        "\n",
        "    def get_config(self):\n",
        "        return {} # Constraint sederhana tidak butuh konfigurasi khusus\n",
        "\n",
        "model_custom_constraint = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", kernel_constraint=NonNegWeights(), # Menggunakan instance dari kelas kustom\n",
        "                        input_shape=X_train_scaled_housing.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model_custom_constraint.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "print(\"Melatih model dengan constraint kustom...\")\n",
        "model_custom_constraint.fit(X_train_scaled_housing, y_train_housing, epochs=5, verbose=0)\n",
        "print(\"Model dengan constraint kustom berhasil dilatih.\")\n",
        "\n",
        "\n",
        "# --- 3. Model Kustom (menggunakan subclassing keras.Model) ---\n",
        "# Contoh: Model dengan residual connections\n",
        "\n",
        "print(\"\\n--- Model Kustom (Subclassing keras.Model) ---\")\n",
        "class ResidualBlock(keras.layers.Layer):\n",
        "    def __init__(self, n_neurons, activation, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden1 = keras.layers.Dense(n_neurons, activation=activation, kernel_initializer=\"he_normal\")\n",
        "        self.hidden2 = keras.layers.Dense(n_neurons, activation=activation, kernel_initializer=\"he_normal\")\n",
        "        # Perhatikan bahwa residual block harus mengembalikan bentuk yang sama dengan inputnya\n",
        "        # Jika input dan output dari hidden layers tidak sama, perlu proyeksi linier (1x1 conv/dense)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = self.hidden1(inputs)\n",
        "        Z = self.hidden2(Z)\n",
        "        # Residual connection: pastikan inputs dan Z memiliki dimensi yang kompatibel\n",
        "        # Jika dimensi berubah, tambahkan lapisan Dense atau konvolusi untuk menyamakan\n",
        "        if inputs.shape[-1] != Z.shape[-1]: # Contoh penanganan jika dimensi tidak cocok\n",
        "            inputs = keras.layers.Dense(Z.shape[-1], activation=None)(inputs) # Proyeksi linier\n",
        "        return inputs + Z\n",
        "\n",
        "class ResidualDNN(keras.Model):\n",
        "    def __init__(self, n_hidden_blocks, n_neurons_per_block, output_neurons, activation=\"relu\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.initial_dense = keras.layers.Dense(n_neurons_per_block, activation=activation, kernel_initializer=\"he_normal\")\n",
        "        self.blocks = [ResidualBlock(n_neurons_per_block, activation, name=f\"res_block_{i}\")\n",
        "                       for i in range(n_hidden_blocks)]\n",
        "        self.output_layer = keras.layers.Dense(output_neurons)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.initial_dense(inputs)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "# Membuat dan melatih model ResidualDNN\n",
        "# Perhatikan bahwa input_shape perlu diberikan saat membuat instance untuk .build() atau pertama kali .call()\n",
        "model_custom_subclass = ResidualDNN(n_hidden_blocks=3, n_neurons_per_block=50, output_neurons=1)\n",
        "\n",
        "# Membangun model agar summary bisa muncul\n",
        "model_custom_subclass.build(input_shape=(None, X_train_scaled_housing.shape[1])) # (None, num_features)\n",
        "\n",
        "print(\"\\nRingkasan Model Kustom (ResidualDNN):\")\n",
        "model_custom_subclass.summary()\n",
        "\n",
        "model_custom_subclass.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "print(\"\\nMelatih model kustom (subclassing)...\")\n",
        "history_custom_subclass = model_custom_subclass.fit(X_train_scaled_housing, y_train_housing, epochs=10,\n",
        "                                                      validation_data=(X_valid_scaled_housing, y_valid_housing), verbose=0)\n",
        "print(\"Model kustom (subclassing) berhasil dilatih.\")\n",
        "\n",
        "\n",
        "# --- 4. Loop Pelatihan Kustom (Custom Training Loops) ---\n",
        "# Menggunakan tf.GradientTape untuk kontrol penuh.\n",
        "\n",
        "print(\"\\n--- Loop Pelatihan Kustom ---\")\n",
        "\n",
        "# a. Definisikan Model (sederhana)\n",
        "keras.backend.clear_session() # Hapus graph sebelumnya\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "l2_reg = keras.regularizers.l2(0.05)\n",
        "model_custom_loop = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg,\n",
        "                        input_shape=X_train_scaled_housing.shape[1:]),\n",
        "    keras.layers.Dense(1, kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)\n",
        "])\n",
        "\n",
        "# b. Definisikan Hyperparameter Pelatihan\n",
        "optimizer_custom_loop = keras.optimizers.Nadam(learning_rate=0.001)\n",
        "loss_fn_custom_loop = keras.losses.MeanSquaredError()\n",
        "\n",
        "mean_loss = keras.metrics.Mean()\n",
        "mean_val_loss = keras.metrics.Mean()\n",
        "\n",
        "# c. Loop Pelatihan Manual\n",
        "n_epochs_custom_loop = 10\n",
        "batch_size_custom_loop = 32\n",
        "\n",
        "# Mengatur dataset ke dalam tf.data.Dataset\n",
        "train_set = tf.data.Dataset.from_tensor_slices((X_train_scaled_housing, y_train_housing)).shuffle(1000).batch(batch_size_custom_loop).prefetch(1)\n",
        "valid_set = tf.data.Dataset.from_tensor_slices((X_valid_scaled_housing, y_valid_housing)).batch(batch_size_custom_loop).prefetch(1)\n",
        "\n",
        "print(\"\\nMemulai loop pelatihan kustom...\")\n",
        "for epoch in range(n_epochs_custom_loop):\n",
        "    # Loop pelatihan\n",
        "    for X_batch, y_batch in train_set:\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model_custom_loop(X_batch, training=True) # training=True untuk layer seperti Dropout/BN\n",
        "            main_loss = loss_fn_custom_loop(y_batch, y_pred)\n",
        "            # Menambahkan loss regularisasi manual (jika ada)\n",
        "            loss = tf.add_n([main_loss] + model_custom_loop.losses)\n",
        "\n",
        "        # Hitung gradien\n",
        "        gradients = tape.gradient(loss, model_custom_loop.trainable_variables)\n",
        "\n",
        "        # Update bobot\n",
        "        optimizer_custom_loop.apply_gradients(zip(gradients, model_custom_loop.trainable_variables))\n",
        "\n",
        "        # Update metrik\n",
        "        mean_loss(loss) # Pass loss total (termasuk regularisasi)\n",
        "\n",
        "    # Loop validasi\n",
        "    for X_batch_val, y_batch_val in valid_set:\n",
        "        y_pred_val = model_custom_loop(X_batch_val)\n",
        "        val_loss = loss_fn_custom_loop(y_batch_val, y_pred_val)\n",
        "        # Tidak perlu menambahkan loss regularisasi untuk validasi, hanya main loss\n",
        "        mean_val_loss(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{n_epochs_custom_loop} - Loss: {mean_loss.result():.4f}, Val_loss: {mean_val_loss.result():.4f}\")\n",
        "\n",
        "    # Reset metrik untuk epoch berikutnya\n",
        "    mean_loss.reset_state()\n",
        "    mean_val_loss.reset_state()\n",
        "\n",
        "print(\"Loop pelatihan kustom selesai.\")\n",
        "\n",
        "# --- 5. Layer Kustom ---\n",
        "# Contoh: Sebuah layer kustom yang tidak hanya melakukan operasi Dense,\n",
        "# tapi juga memiliki logika internal khusus.\n",
        "\n",
        "print(\"\\n--- Layer Kustom ---\")\n",
        "class DenseWithActivationAndBiasConstraint(keras.layers.Layer):\n",
        "    def __init__(self, units, activation=None, bias_constraint=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.bias_constraint = keras.constraints.get(bias_constraint)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(\n",
        "            name=\"kernel\",\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer=\"he_normal\",\n",
        "            trainable=True\n",
        "        )\n",
        "        self.bias = self.add_weight(\n",
        "            name=\"bias\",\n",
        "            shape=(self.units,),\n",
        "            initializer=\"zeros\",\n",
        "            trainable=True,\n",
        "            constraint=self.bias_constraint\n",
        "        )\n",
        "        super().build(input_shape) # Wajib panggil ini di akhir build()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = tf.matmul(inputs, self.kernel) + self.bias\n",
        "        if self.activation is not None:\n",
        "            Z = self.activation(Z)\n",
        "        return Z\n",
        "\n",
        "    def get_config(self):\n",
        "        # Penting untuk menyimpan dan memulihkan layer kustom\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"units\": self.units,\n",
        "            \"activation\": keras.activations.serialize(self.activation),\n",
        "            \"bias_constraint\": keras.constraints.serialize(self.bias_constraint),\n",
        "        })\n",
        "        return config\n",
        "\n",
        "# Membuat dan melatih model dengan layer kustom\n",
        "model_custom_layer = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    DenseWithActivationAndBiasConstraint(300, activation=\"relu\", bias_constraint=\"NonNeg\", name=\"my_custom_dense_layer\"),\n",
        "    DenseWithActivationAndBiasConstraint(100, activation=\"relu\", name=\"my_custom_dense_layer_2\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model_custom_layer.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "print(\"\\nMelatih model dengan layer kustom...\")\n",
        "history_custom_layer = model_custom_layer.fit(X_train_fashion, y_train_fashion, epochs=5, verbose=0)\n",
        "print(\"Model dengan layer kustom berhasil dilatih.\")\n",
        "\n",
        "# Menyimpan dan memuat model dengan layer kustom (membutuhkan custom_objects)\n",
        "model_custom_layer.save(\"my_custom_layer_model.h5\")\n",
        "print(\"\\nModel dengan layer kustom disimpan. Mencoba memuat...\")\n",
        "try:\n",
        "    loaded_custom_layer_model = keras.models.load_model(\n",
        "        \"my_custom_layer_model.h5\",\n",
        "        custom_objects={\"DenseWithActivationAndBiasConstraint\": DenseWithActivationAndBiasConstraint,\n",
        "                        \"NonNegWeights\": NonNegWeights} # FIX: Tambahkan NonNegWeights ke custom_objects\n",
        "    )\n",
        "    print(\"Model dengan layer kustom berhasil dimuat.\")\n",
        "    # Verifikasi dengan summary\n",
        "    loaded_custom_layer_model.summary()\n",
        "except Exception as e:\n",
        "    print(f\"Gagal memuat model dengan layer kustom: {e}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Selesai Reproduksi Kode Chapter 12 ---\")\n"
      ]
    }
  ]
}